W1104 01:15:16.567000 853384 site-packages/torch/distributed/run.py:774] 
W1104 01:15:16.567000 853384 site-packages/torch/distributed/run.py:774] *****************************************
W1104 01:15:16.567000 853384 site-packages/torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1104 01:15:16.567000 853384 site-packages/torch/distributed/run.py:774] *****************************************
/home/Tenemin/Project/CasCoD/./finetuning.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging
/home/Tenemin/Project/CasCoD/./finetuning.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging
/home/Tenemin/Project/CasCoD/./finetuning.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import packaging
/home/Tenemin/Project/CasCoD/src/model_checkpointing/checkpoint_handler.py:18: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  from torch.distributed._shard.checkpoint import (
/home/Tenemin/Project/CasCoD/src/model_checkpointing/checkpoint_handler.py:18: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  from torch.distributed._shard.checkpoint import (
/home/Tenemin/Project/CasCoD/src/model_checkpointing/checkpoint_handler.py:18: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead
  from torch.distributed._shard.checkpoint import (
INFO 11-04 01:15:19 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 01:15:19 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 01:15:19 [__init__.py:216] Automatically detected platform cuda.
Warning: unknown parameter fsdp_activation_checkpointing
Warning: unknown parameter pure_bf16
Warning: unknown parameter optimizer
Warning: unknown parameter peft_model
Warning: unknown parameter max_new_tokens
Warning: unknown parameter prompt_file
Warning: unknown parameter do_sample
Warning: unknown parameter min_length
Warning: unknown parameter use_cache
Warning: unknown parameter top_p
Warning: unknown parameter temperature
Warning: unknown parameter top_k
Warning: unknown parameter repetition_penalty
Warning: unknown parameter length_penalty
Warning: unknown parameter enable_azure_content_safety
Warning: unknown parameter enable_sensitive_topics
Warning: unknown parameter enable_salesforce_content_safety
Warning: unknown parameter max_padding_length
local rank 1
rank 1
world size 3
Warning: unknown parameter fsdp_activation_checkpointing
Warning: unknown parameter pure_bf16
Warning: unknown parameter optimizer
Warning: unknown parameter peft_model
Warning: unknown parameter max_new_tokens
Warning: unknown parameter prompt_file
Warning: unknown parameter do_sample
Warning: unknown parameter min_length
Warning: unknown parameter use_cache
Warning: unknown parameter top_p
Warning: unknown parameter temperature
Warning: unknown parameter top_k
Warning: unknown parameter repetition_penalty
Warning: unknown parameter length_penalty
Warning: unknown parameter enable_azure_content_safety
Warning: unknown parameter enable_sensitive_topics
Warning: unknown parameter enable_salesforce_content_safety
Warning: unknown parameter max_padding_length
local rank 2
rank 2
world size 3
Warning: unknown parameter fsdp_activation_checkpointing
Warning: unknown parameter pure_bf16
Warning: unknown parameter optimizer
Warning: unknown parameter peft_model
Warning: unknown parameter max_new_tokens
Warning: unknown parameter prompt_file
Warning: unknown parameter do_sample
Warning: unknown parameter min_length
Warning: unknown parameter use_cache
Warning: unknown parameter top_p
Warning: unknown parameter temperature
Warning: unknown parameter top_k
Warning: unknown parameter repetition_penalty
Warning: unknown parameter length_penalty
Warning: unknown parameter enable_azure_content_safety
Warning: unknown parameter enable_sensitive_topics
Warning: unknown parameter enable_salesforce_content_safety
Warning: unknown parameter max_padding_length
local rank 0
rank 0
world size 3
Clearing GPU cache for all ranks
--> Running with torch dist debug set to detail
--> Training Set Length = 2603
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.99s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.93s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.65s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.99s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  3.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.01s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.64s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.98s/it]
--> Model meta-llama/Llama-2-7b-hf

--> meta-llama/Llama-2-7b-hf has 6738.415616 Million params

train cfg ckpt_continue: None
train cfg ckpt_continue: None
trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.4955
bFloat16 enabled for mixed precision - using bfSixteen policy
to fsdp
train cfg ckpt_continue: None
trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.4955
to fsdp
trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.4955
to fsdp
--> applying fsdp activation checkpointing...
/home/Tenemin/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m          [0m| 0/13 [00:00<?, ?it/s]--> applying fsdp activation checkpointing...
/home/Tenemin/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m          [0m| 0/13 [00:00<?, ?it/s]--> applying fsdp activation checkpointing...
/home/Tenemin/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m          [0m| 0/13 [00:00<?, ?it/s]